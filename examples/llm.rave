// Implementation on C taked from https://github.com/karpathy/llm.c/blob/master/train_gpt2.c

import <std/io> <std/math> <std/ascii>

void encoderForward(float* out, int* inp, float* wte, float* wpe, int B, int T, int C) {
    // out is (B,T,C). At each position (b,t), a C-dimensional vector summarizing token & position
    // inp is (B,T) of integers, holding the token ids at each (b,t) position
    // wte is (V,C) of token embeddings, short for "weight token embeddings"
    // wpe is (maxT,C) of position embeddings, short for "weight positional embedding"
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            // seek to the output position in out[b,t,:]
            float* out_bt = itop(float*, ptoi(out_bt) + b * T * C + t * C);
            // get the index of the token at inp[b, t]
            int ix = inp[b * T + t];
            // seek to the position in wte corresponding to the token
            float* wte_ix = itop(float*, ptoi(wte) + ix * C);
            // seek to the position in wpe corresponding to the position
            float* wpe_t = itop(float*, ptoi(wpe) + t * C);
            // add the two vectors and store the result in out[b,t,:]
            for(int i=0; i<C; i++) out_bt[i] = wte_ix[i] + wpe_t[i];
        }
    }
}

void encoderBackward(float* dwte, float* dwpe, float* dout, int* inp, int B, int T, int C) {
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            float* dout_bt = itop(float*, ptoi(dout) + b * T * C + t * C);
            int ix = inp[b * T + t];
            float* dwte_ix = itop(float*, ptoi(dwte) + ix * C);
            float* dwpe_t = itop(float*, ptoi(dwpe) + t * C);
            for(int i=0; i<C; i++) {
                float d = dout_bt[i];
                dwte_ix[i] += d;
                dwpe_t[i] += d;
            }
        }
    }
}

void layernormForward(float* out, float* mean, float* rstd, float* inp, float* weight, float* bias, int B, int T, int C) {
    // reference: https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html
    // both inp and out are (B,T,C) of the activations
    // mean and rstd are (B,T) buffers, to be used later in backward pass
    // at each position (b,t) of the input, the C-dimensional vector
    // of activations gets normalized, then scaled and shifted
    float eps = cast(float)0.00001;
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            // seek to the input position inp[b,t,:]
            float* x = itop(float*, ptoi(inp) + b * T * C + t * C);
            // calculate the mean
            float m = cast(float)0.0;
            for(int i=0; i<C; i++) m += x[i];
            m = m/C;
            // calculate the variance (without any bias correction)
            float v = cast(float)0.0;
            for(int i=0; i<C; i++) {
                float xshift = x[i] - m;
                v += xshift * xshift;
            }
            v = v/C;
            // calculate the rstd (reciprocal standard deviation)
            float s = cast(float)1.0 / cast(float)std::math::sqrt(cast(double)(v + eps));
            // seek to the output position in out[b,t,:]
            float* out_bt = itop(float*, ptoi(out) + b * T * C + t * C);
            for(int i=0; i<C; i++) {
                float n = (s * (x[i] - m)); // normalize
                float o = n * weight[i] + bias[i]; // scale and shift
                out_bt[i] = o; // write
            }
            // cache the mean and rstd for the backward pass later
            mean[b * T + t] = m;
            rstd[b * T + t] = s;
        }
    }
}

void layernormBackward(float* dinp, float* dweight, float* dbias, float* dout, float* inp, float* weight, float* mean, float* rstd, int B, int T, int C) {
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            float* dout_bt = itop(float*, ptoi(dout) + b * T * C + t * C);
            float* inp_bt = itop(float*, ptoi(inp) + b * T * C + t * C);
            float* dinp_bt = itop(float*, ptoi(dinp) + b * T * C + t * C);
            float mean_bt = mean[b * T + t];
            float rstd_bt = rstd[b * T + t];

            // first: two reduce operations
            float dnorm_mean = cast(float)0.0;
            float dnorm_norm_mean = cast(float)0.0;
            for(int i=0; i<C; i++) {
                float norm_bti = (inp_bt[i] - mean_bt) * rstd_bt;
                float dnorm_i = weight[i] * dout_bt[i];
                dnorm_mean += dnorm_i;
                dnorm_norm_mean += dnorm_i * norm_bti;
            }
            dnorm_mean = dnorm_mean / C;
            dnorm_norm_mean = dnorm_norm_mean / C;

            // now iterate again and accumulate all the gradients
            for(int i=0; i<C; i++) {
                float norm_bti = (inp_bt[i] - mean_bt) * rstd_bt;
                float dnorm_i = weight[i] * dout_bt[i];
                // gradient contribution to bias
                dbias[i] += dout_bt[i];
                // gradient contribution to weight
                dweight[i] += norm_bti * dout_bt[i];
                // gradient contribution to input
                float dval = cast(float)0.0;
                dval += dnorm_i; // term 1
                dval -= dnorm_mean; // term 2
                dval -= norm_bti * dnorm_norm_mean; // term 3
                dval *= rstd_bt; // final scale
                dinp_bt[i] += dval;
            }
        }
    }
}

void matmulForward(float* out, float* inp, float* weight, float* bias, int B, int T, int C, int OC) {
    // most of the running time is spent here and in matmul_backward
    // OC is short for "output channels"
    // inp is (B,T,C), weight is (OC, C), bias is (OC)
    // out will be (B,T,OC)

    for(int b=0; b<B;b++) {
        for(int t=0; t<T; t++) {
            float* out_bt = itop(float*, ptoi(out) + b * T * OC + t * OC);
            float* inp_bt = itop(float*, ptoi(inp) + b * T * C + t * C);
            for(int o = 0; o < OC; o++) {
                float val;
                if(bias != cast(float*)null) val = bias[o];

                float* wrow = itop(float*, ptoi(weight) + o*C);
                for(int i = 0; i < C; i++) val += inp_bt[i] * wrow[i];
                out_bt[o] = val;
            }
        }
    }
}

void matmulBackward(float* dinp, float* dweight, float* dbias, float* dout, float* inp, float* weight, int B, int T, int C, int OC) {
    // most of the running time is spent here and in matmul_forward
    // this backward could be done in a single "round" of loops
    // but that doesn't afford an efficient parallelization strategy

    // backward into inp first, parallelize over B,T

    for (int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            float* dout_bt = itop(float*, ptoi(dout) + b * T * OC + t * OC);
            float* dinp_bt = itop(float*, ptoi(dinp) + b * T * C + t * C);
            for(int o=0; o<OC; o++) {
                float* wrow = itop(float*, ptoi(weight) + o*C);
                float d = dout_bt[o];
                for(int i = 0; i < C; i++) dinp_bt[i] += wrow[i] * d;
            }
        }
    }
    // backward into weight/bias, parallelize over output channels OC

    for(int o=0; o<OC; o++) {
        for(int b=0; b<B; b++) {
            for(int t=0; t<T; t++) {
                float* dout_bt = itop(float*, ptoi(dout) + b * T * OC + t * OC);
                float* inp_bt = itop(float*, ptoi(inp) + b * T * C + t * C);
                float* dwrow = itop(float*, ptoi(dweight) + o*C);
                float d = dout_bt[o];
                if(dbias != cast(float*)null) dbias[o] += d;
                for(int i = 0; i < C; i++) dwrow[i] += inp_bt[i] * d;
            }
        }
    }
}

void attentionForward(float* out, float* preatt, float* att, float* inp, int B, int T, int C, int NH) {
    // input is (B, T, 3C) holding the query, key, value (Q, K, V) vectors
    // preatt, att are (B, NH, T, T). NH = number of heads, T = sequence length
    // that holds the pre-attention and post-attention scores (used in backward)
    // output is (B, T, C)
    // attention is the only layer that mixes information across time
    // every other operation is applied at every (b,t) position independently
    // (and of course, no layer mixes information across batch)
    int C3 = C*3;
    int hs = C / NH; // head size
    float scale = cast(float)(1.0 / std::math::sqrt(cast(double)hs));

    for(int b= 0; b<B; b++) {
        for(int t=0; t<T; t++) {
            for(int h=0; h<NH; h++) {
                float* query_t = itop(float*, ptoi(inp) + b * T * C3 + t * C3 + h * hs);
                float* preatt_bth = itop(float*, ptoi(preatt) + b*NH*T*T + h*T*T + t*T);
                float* att_bth = itop(float*, ptoi(att) + b*NH*T*T + h*T*T + t*T);

                // pass 1: calculate query dot key and maxval
                float maxval = cast(float)(-10000.0); // TODO something better
                for(int t2=0; t2<=t; t2++) {
                    float* key_t2 = itop(float*, ptoi(inp) + b * T * C3 + t2 * C3 + h * hs + C); // +C because it's key

                    // (query_t) dot (key_t2)
                    float val;
                    for(int i=0; i<hs; i++) val += query_t[i] * key_t2[i];
                    val = val * scale;
                    if(val > maxval) maxval = val;
                    preatt_bth[t2] = val;
                }

                // pass 2: calculate the exp and keep track of sum
                // maxval is being calculated and subtracted only for numerical stability
                float expsum;
                for(int t2=0; t2<=t; t2++) {
                    float expv = std::math::exp(cast(double)(preatt_bth[t2] - maxval));
                    expsum += expv;
                    att_bth[t2] = expv;
                }
                float expsum_inv;
                if(expsum != 0.0) expsum_inv = cast(float)(1.0 / expsum);

                // pass 3: normalize to get the softmax
                for(int t2=0; t2<T; t2++) {
                    if(t2 <= t) {
                        att_bth[t2] = att_bth[t2] * expsum_inv;
                    } else {
                        // causal attention mask. not strictly necessary to set to zero here
                        // only doing this explicitly for debugging and checking to PyTorch
                        att_bth[t2] = cast(float)0.0;
                    }
                }

                // pass 4: accumulate weighted values into the output of attention
                float* out_bth = itop(float*, ptoi(out) + b * T * C + t * C + h * hs);
                for(int i=0; i<hs; i++) out_bth[i] = cast(float)0.0;
                for(int t2=0; t2<=t; t2++) {
                    float* value_t2 = itop(float*, ptoi(inp) + b * T * C3 + t2 * C3 + h * hs + C*2); // +C*2 because it's value
                    float att_btht2 = att_bth[t2];
                    for(int i=0; i<hs; i++) out_bth[i] += att_btht2 * value_t2[i];
                }
            }
        }
    }
}

void attentionBackward(float* dinp, float* dpreatt, float* datt, float* dout, float* inp, float* att, int B, int T, int C, int NH) {
    // inp/dinp are (B, T, 3C) Q,K,V
    // att/datt/dpreatt are (B, NH, T, T)
    // dout is (B, T, C)
    int C3 = C*3;
    int hs = C / NH; // head size
    float scale = cast(float)(1.0 / std::math::sqrt(cast(double)hs));

    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            for(int h=0; h<NH; h++) {
                float* att_bth = itop(float*, ptoi(att) + b*NH*T*T + h*T*T + t*T);
                float* datt_bth = itop(float*, ptoi(datt) + b*NH*T*T + h*T*T + t*T);
                float* dpreatt_bth = itop(float*, ptoi(dpreatt) + b*NH*T*T + h*T*T + t*T);
                float* dquery_t = itop(float*, ptoi(dinp) + b * T * C3 + t * C3 + h * hs);
                float* query_t = itop(float*, ptoi(inp) + b * T * C3 + t * C3 + h * hs);

                // backward pass 4, through the value accumulation
                float* dout_bth = itop(float*, ptoi(dout) + b * T * C + t * C + h * hs);
                for(int t2=0; t2<=t; t2++) {
                    float* value_t2 = itop(float*, ptoi(inp) + b * T * C3 + t2 * C3 + h * hs + C*2); // +C*2 because it's value
                    float* dvalue_t2 = itop(float*, ptoi(dinp) + b * T * C3 + t2 * C3 + h * hs + C*2);
                    for(int i=0; i<hs; i++) {
                        // in the forward pass this was:
                        // out_bth[i] += att_bth[t2] * value_t2[i];
                        // so now we have:
                        datt_bth[t2] += value_t2[i] * dout_bth[i];
                        dvalue_t2[i] += att_bth[t2] * dout_bth[i];
                    }
                }

                // backward pass 2 & 3, the softmax
                // note that softmax (like e.g. tanh) doesn't need the input (preatt) to backward
                for(int t2=0; t2<=t; t2++) {
                    for(int t3=0; t3<=t; t3++) {
                        float indicator;
                        if(t2 == t3) indicator = cast(float)1.0;
                        float local_derivative = att_bth[t2] * (indicator - att_bth[t3]);
                        dpreatt_bth[t3] += local_derivative * datt_bth[t2];
                    }
                }

                // backward pass 1, the query @ key matmul
                for(int t2=0; t2<=t; t2++) {
                    float* key_t2 = itop(float*, ptoi(inp) + b * T * C3 + t2 * C3 + h * hs + C); // +C because it's key
                    float* dkey_t2 = itop(float*, ptoi(dinp) + b * T * C3 + t2 * C3 + h * hs + C); // +C because it's key
                    for(int i=0; i<hs; i++) {
                        // in the forward pass this was:
                        // preatt_bth[t2] += (query_t[i] * key_t2[i]) * scale;
                        // so now we have:
                        dquery_t[i] += key_t2[i] * dpreatt_bth[t2] * scale;
                        dkey_t2[i] += query_t[i] * dpreatt_bth[t2] * scale;
                    }
                }
            }
        }
    }
}

alias geluScalingFactor = std::math::sqrt(cast(double)(2.0 / std::math::PI));

void geluForward(float* out, float* inp, int N) {
    // (approximate) GeLU elementwise non-linearity in the MLP block of Transformer
    for(int i=0; i<N; i++) {
        float x = inp[i];
        float cube = cast(float)0.044715 * x * x * x;
        out[i] = cast(float)0.5 * x * (cast(float)1.0 + std::math::tanh(cast(double)(geluScalingFactor * (x + cube))));
    }
}

void geluBackward(float* dinp, float* inp, float* dout, int N) {
    for(int i=0; i<N; i++) {
        float x = inp[i];
        float cube = cast(float)0.044715 * x * x * x;
        float tanh_arg = geluScalingFactor * (x + cube);
        float tanh_out = std::math::tanh(cast(double)tanh_arg);
        float coshf_out = std::math::cosh(cast(double)tanh_arg);
        float sech_out = cast(float)1.0 / (coshf_out * coshf_out);
        float local_grad = cast(float)0.5 * (cast(float)1.0 + tanh_out) + x * cast(float)0.5 * sech_out * geluScalingFactor * (cast(float)1.0 + cast(float)3.0 * cast(float)0.044715 * x * x);
        dinp[i] += local_grad * dout[i];
    }
}

void residualForward(float* out, float* inp1, float* inp2, int N) {
    for(int i=0; i<N; i++) out[i] = inp1[i] + inp2[i];
}

void residualBackward(float* dinp1, float* dinp2, float* dout, int N) {
    for(int i=0; i<N; i++) {
        dinp1[i] += dout[i];
        dinp2[i] += dout[i];
    }
}

void softmaxForward(float* probs, float* logits, int B, int T, int V) {
    // output: probs are (B,T,V) of the probabilities (sums to 1.0 in each b,t position)
    // input: logits is (B,T,V) of the unnormalized log probabilities
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            // probs <- softmax(logits)
            float* logits_bt = itop(float*, ptoi(logits) + b * T * V + t * V);
            float* probs_bt = itop(float*, ptoi(probs) + b * T * V + t * V);

            // maxval is only calculated and subtracted for numerical stability
            float maxval = cast(float)-10000.0; // TODO something better
            for(int i = 0; i < V; i++) {
                if(logits_bt[i] > maxval) maxval = logits_bt[i];
            }
            float sum;
            for(int i=0; i<V; i++) {
                probs_bt[i] = std::math::exp(cast(double)(logits_bt[i] - maxval));
                sum += probs_bt[i];
            }
            for(int i=0; i<V; i++) probs_bt[i] = probs_bt[i] / sum;
        }
    }
}

void crossentropyForward(float* losses, float* probs, int* targets, int B, int T, int V) {
    // output: losses is (B,T) of the individual losses at each position
    // input: probs are (B,T,V) of the probabilities
    // input: targets is (B,T) of integers giving the correct index in logits
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            // loss = -log(probs[target])
            float* probs_bt = itop(float*, ptoi(probs) + b * T * V + t * V);
            int ix = targets[b * T + t];
            losses[b * T + t] = -std::math::log(cast(double)probs_bt[ix]);
        }
    }
}

void crossentropySoftmaxBackward(float* dlogits, float* dlosses, float* probs, int* targets, int B, int T, int V) {
    // backwards through both softmax and crossentropy
    for(int b=0; b<B; b++) {
        for(int t=0; t<T; t++) {
            float* dlogits_bt = itop(float*, ptoi(dlogits) + b * T * V + t * V);
            float* probs_bt = itop(float*, ptoi(probs) + b * T * V + t * V);
            float dloss = dlosses[b * T + t];
            int ix = targets[b * T + t];
            for(int i=0; i<V; i++) {
                float p = probs_bt[i];
                float indicator;
                if(i == ix) indicator = cast(float)1.0;
                dlogits_bt[i] += (p - indicator) * dloss;
            }
        }
    }
}

struct ParameterTensors {
    float* wte; // (V, C)
    float* wpe; // (maxT, C)
    float* ln1w; // (L, C)
    float* ln1b; // (L, C)
    float* qkvw; // (L, 3*C, C)
    float* qkvb; // (L, 3*C)
    float* attprojw; // (L, C, C)
    float* attprojb; // (L, C)
    float* ln2w; // (L, C)
    float* ln2b; // (L, C)
    float* fcw; // (L, 4*C, C)
    float* fcb; // (L, 4*C)
    float* fcprojw; // (L, C, 4*C)
    float* fcprojb; // (L, C)
    float* lnfw; // (C)
    float* lnfb; // (C)
}

// allocate memory for the parameters and point the individual tensors to the right places
float* mallocAndPointParameters(ParameterTensors* params, int* param_sizes) {
    int num_parameters = 0;
    for(int i=0; i<16; i++) num_parameters += param_sizes[i];
    // malloc all parameters all at once
    return = cast(float*)std::malloc(num_parameters * sizeof(float));
    // assign all the tensors
    float**[16] ptrs = [
        params.&wte, params.&wpe, params.&ln1w, params.&ln1b, params.&qkvw, params.&qkvb,
        params.&attprojw, params.&attprojb, params.&ln2w, params.&ln2b, params.&fcw, params.&fcb,
        params.&fcprojw, params.&fcprojb, params.&lnfw, params.&lnfb
    ];
    float* params_memory_iterator = return;
    for(int i=0; i<16; i++) {
        ptrs[i][0] = params_memory_iterator;
        params_memory_iterator = itop(float*, ptoi(params_memory_iterator) + param_sizes[i]);
    }
}

struct ActivationTensors {
    float* encoded; // (B, T, C)
    float* ln1; // (L, B, T, C)
    float* ln1_mean; // (L, B, T)
    float* ln1_rstd; // (L, B, T)
    float* qkv; // (L, B, T, 3*C)
    float* atty; // (L, B, T, C)
    float* preatt; // (L, B, NH, T, T)
    float* att; // (L, B, NH, T, T)
    float* attproj; // (L, B, T, C)
    float* residual2; // (L, B, T, C)
    float* ln2; // (L, B, T, C)
    float* ln2_mean; // (L, B, T)
    float* ln2_rstd; // (L, B, T)
    float* fch; // (L, B, T, 4*C)
    float* fch_gelu; // (L, B, T, 4*C)
    float* fcproj; // (L, B, T, C)
    float* residual3; // (L, B, T, C)
    float* lnf; // (B, T, C)
    float* lnf_mean; // (B, T)
    float* lnf_rstd; // (B, T)
    float* logits; // (B, T, V)
    float* probs; // (B, T, V)
    float* losses; // (B, T)
}

float* mallocAndPointActivations(ActivationTensors* acts, int* act_sizes) {
    int num_activations = 0;
    for(int i=0; i<23; i++) num_activations += act_sizes[i];
    return = cast(float*)std::malloc(num_activations * sizeof(float));
    float**[23] ptrs = [
        acts.&encoded, acts.&ln1, acts.&ln1_mean, acts.&ln1_rstd, acts.&qkv, acts.&atty,
        acts.&preatt, acts.&att, acts.&attproj, acts.&residual2, acts.&ln2, acts.&ln2_mean,
        acts.&ln2_rstd, acts.&fch, acts.&fch_gelu, acts.&fcproj, acts.&residual3, acts.&lnf,
        acts.&lnf_mean, acts.&lnf_rstd, acts.&logits, acts.&probs, acts.&losses
    ];
    float* acts_memory_iterator = return;
    for(int i=0; i<23; i++) {
        ptrs[i][0] = acts_memory_iterator;
        acts_memory_iterator = itop(float*, ptoi(acts_memory_iterator) + act_sizes[i]);
    }
}


struct GPT2Config {
    int max_seq_len; // max sequence length, e.g. 1024
    int vocab_size; // vocab size, e.g. 50257
    int num_layers; // number of layers, e.g. 12
    int num_heads; // number of heads in attention, e.g. 12
    int channels; // number of channels, e.g. 768
}

struct GPT2 {
    GPT2Config config;
    // the weights (parameters) of the model, and their sizes
    ParameterTensors params;
    int[16] param_sizes;
    float* params_memory;
    int num_parameters;
    // gradients of the weights
    ParameterTensors grads;
    float* grads_memory;
    // buffers for the AdamW optimizer
    float* m_memory;
    float* v_memory;
    // the activations of the model, and their sizes
    ActivationTensors acts;
    int[23] act_sizes;
    float* acts_memory;
    int num_activations;
    // gradients of the activations
    ActivationTensors grads_acts;
    float* grads_acts_memory;
    // other run state configuration
    int batch_size; // the batch size (B) of current forward pass
    int seq_len; // the sequence length (T) of current forward pass
    int* inputs; // the input tokens for the current forward pass
    int* targets; // the target tokens for the current forward pass
    float mean_loss; // after a forward pass with targets, will be populated with the mean loss
}

void gpt2BuildFromCheckpoint(GPT2* model, char* checkpoint_path) {

    // read in model from a checkpoint file
    std::file modelFile = std::file(checkpoint_path);
    modelFile.open("rb");

    if(!(modelFile.isOpen)) {std::println("Error opening model file"); std::exit(1);}
    int[256] model_header;


    modelFile.read(cast(void*)&model_header, sizeof(int), 256);

    if(model_header[0] != 20240326) {std::println("Bad magic model file"); std::exit(1);}
    if(model_header[1] != 1) {std::println("Bad version in model file"); std::exit(1);}

    // read in hyperparameters
    int maxT; int V;
    int L; int NH;
    int C;
    
    maxT = model_header[2];
    V = model_header[3];
    L = model_header[4];
    NH = model_header[5];
    C = model_header[6];

    model.config.max_seq_len = maxT;
    model.config.vocab_size = V;
    model.config.num_layers = L;
    model.config.num_heads = NH;
    model.config.channels = C;

    std::println("[GPT-2]");
    std::println("max_seq_len: ", maxT);
    std::println("vocab_size: ", V);
    std::println("num_layers: ", L);
    std::println("num_heads: ", NH);
    std::println("channels: ", C);

    // allocate space for all the parameters and read them in
    model.param_sizes[0] = V * C; // wte
    model.param_sizes[1] = maxT * C; // wpe
    model.param_sizes[2] = L * C; // ln1w
    model.param_sizes[3] = L * C; // ln1b
    model.param_sizes[4] = L * (3 * C) * C; // qkvw
    model.param_sizes[5] = L * (3 * C); // qkvb
    model.param_sizes[6] = L * C * C; // attprojw
    model.param_sizes[7] = L * C; // attprojb
    model.param_sizes[8] = L * C; // ln2w
    model.param_sizes[9] = L * C; // ln2b
    model.param_sizes[10] = L * (4 * C) * C; // fcw
    model.param_sizes[11] = L * (4 * C); // fcb
    model.param_sizes[12] = L * C * (4 * C); // fcprojw
    model.param_sizes[13] = L * C; // fcprojb
    model.param_sizes[14] = C; // lnfw
    model.param_sizes[15] = C; // lnfb

    // count the number of parameters
    int num_parameters = 0;
    for(int i=0; i<16; i++) num_parameters += model.param_sizes[i];
    std::println("num_parameters: ", num_parameters / cast(float)1000000, "M");
    model.num_parameters = num_parameters;

    // read in all the parameters from file
    model.params_memory = mallocAndPointParameters(model.&params, cast(int*)(model.&param_sizes));
    modelFile.read(cast(void*)(model.&params_memory), sizeof(float), num_parameters);
    modelFile.close();

    // other inits
    model.acts_memory = cast(float*)null;
    model.grads_memory = cast(float*)null;
    model.m_memory = cast(float*)null;
    model.v_memory = cast(float*)null;
    model.grads_acts_memory = cast(float*)null;
    model.inputs = cast(int*)null;
    model.targets = cast(int*)null;
    model.batch_size = 0;
    model.seq_len = 0;
    model.mean_loss = cast(float)-1.0; // -1.0f will designate no loss
}

void gpt2Forward(GPT2* model, int* inputs, int* targets, int B, int T) {
    // targets are optional and could be NULL

    // ensure the model was initialized or error out
    if(model.params_memory == cast(float*)null) {
        std::println("Error: model was not initialized properly.\n");
        std::exit(1);
    }

    // convenience parameters
    int V = model.config.vocab_size;
    int L = model.config.num_layers;
    int NH = model.config.num_heads;
    int C = model.config.channels;

    // allocate space for all the activations if needed (done here, lazily)
    if(model.acts_memory == cast(float*)null) {
        // record the current B,T as well
        model.batch_size = B;
        model.seq_len = T;
        // and now allocate the space
        model.act_sizes[0] = B * T * C; // encoded
        model.act_sizes[1] = L * B * T * C; // ln1
        model.act_sizes[2] = L * B * T;  // ln1_mean
        model.act_sizes[3] = L * B * T;  // ln1_rstd
        model.act_sizes[4] = L * B * T * 3*C; // qkv
        model.act_sizes[5] = L * B * T * C;  // atty
        model.act_sizes[6] = L * B * NH * T * T;  // preatt
        model.act_sizes[7] = L * B * NH * T * T;  // att
        model.act_sizes[8] = L * B * T * C; // attproj
        model.act_sizes[9] = L * B * T * C; // residual2
        model.act_sizes[10] = L * B * T * C; // ln2
        model.act_sizes[11] = L * B * T; // ln2_mean
        model.act_sizes[12] = L * B * T; // ln2_rstd
        model.act_sizes[13] = L * B * T * 4*C; // fch
        model.act_sizes[14] = L * B * T * 4*C; // fch_gelu
        model.act_sizes[15] = L * B * T * C; // fcproj
        model.act_sizes[16] = L * B * T * C; // residual3
        model.act_sizes[17] = B * T * C; // lnf
        model.act_sizes[18] = B * T; // lnf_mean
        model.act_sizes[19] = B * T; // lnf_rstd
        model.act_sizes[20] = B * T * V; // logits
        model.act_sizes[21] = B * T * V; // probs
        model.act_sizes[22] = B * T; // losses
        int num_activations = 0;

        for(int i=0; i<23; i++) num_activations += model.act_sizes[i];
        std::println("num_activations: ", num_activations);

        model.num_activations = num_activations;
        model.acts_memory = mallocAndPointActivations(model.&acts, cast(int*)model.&act_sizes);
        // also create memory for caching inputs and targets
        model.inputs = cast(int*)std::malloc(B * T * sizeof(int));
        model.targets = cast(int*)std::malloc(B * T * sizeof(int)); // might be unused if we never have targets but it's small
    } else {
        // validate B,T is consistent with how we've allocated the memory before
        // in principle we could get more clever here in the future, for now this is safest
        if(B != model.batch_size || T != model.seq_len) {
            std::println("Model: B=", model.batch_size, " T=" model.seq_len, " Desired: B=", B, " T=" T);
            std::exit(1);
        }
    }

    // cache the inputs/targets
    std::memcpy(cast(void*)model.inputs, cast(void*)inputs, B * T * sizeof(int));
    if(targets != cast(int*)null) std::memcpy(cast(void*)model.targets, cast(void*)targets, B * T * sizeof(int));

    // forward pass
    ParameterTensors params = model.params; // for brevity
    ActivationTensors acts = model.acts;
    float* residual;
    encoderForward(acts.encoded, inputs, params.wte, params.wpe, B, T, C); // encoding goes into residual[0
    for(int l=0; l<L; l++) {
        if(l == 0) residual = acts.encoded;
        else residual = itop(float*, ptoi(acts.residual3) + (l-1) * B * T * C);

        // get the pointers of the weights for this layer
        float* l_ln1w = itop(float*, ptoi(params.ln1w) + l * C);
        float* l_ln1b = itop(float*, ptoi(params.ln1b) + l * C);
        float* l_qkvw = itop(float*, ptoi(params.qkvw) + l * 3*C * C);
        float* l_qkvb = itop(float*, ptoi(params.qkvb) + l * 3*C);
        float* l_attprojw = itop(float*, ptoi(params.attprojw) + l * C * C);
        float* l_attprojb = itop(float*, ptoi(params.attprojb) + l * C);
        float* l_ln2w = itop(float*, ptoi(params.ln2w) + l * C);
        float* l_ln2b = itop(float*, ptoi(params.ln2b) + l * C);
        float* l_fcw = itop(float*, ptoi(params.fcw) + l * 4*C * C);
        float* l_fcb = itop(float*, ptoi(params.fcb) + l * 4*C);
        float* l_fcprojw = itop(float*, ptoi(params.fcprojw) + l * C * 4*C);
        float* l_fcprojb = itop(float*, ptoi(params.fcprojb) + l * C);

        // get the pointers of the activations for this layer
        float* l_ln1 = itop(float*, ptoi(acts.ln1) + l * B * T * C);
        float* l_ln1_mean = itop(float*, ptoi(acts.ln1_mean) + l * B * T);
        float* l_ln1_rstd = itop(float*, ptoi(acts.ln1_rstd) + l * B * T);
        float* l_qkv = itop(float*, ptoi(acts.qkv) + l * B * T * 3*C);
        float* l_atty = itop(float*, ptoi(acts.atty) + l * B * T * C);
        float* l_preatt = itop(float*, ptoi(acts.preatt) + l * B * NH * T * T);
        float* l_att = itop(float*, ptoi(acts.att) + l * B * NH * T * T);
        float* l_attproj = itop(float*, ptoi(acts.attproj) + l * B * T * C);
        float* l_residual2 = itop(float*, ptoi(acts.residual2) + l * B * T * C);
        float* l_ln2 = itop(float*, ptoi(acts.ln2) + l * B * T * C);
        float* l_ln2_mean = itop(float*, ptoi(acts.ln2_mean) + l * B * T);
        float* l_ln2_rstd = itop(float*, ptoi(acts.ln2_rstd) + l * B * T);
        float* l_fch = itop(float*, ptoi(acts.fch) + l * B * T * 4*C);
        float* l_fch_gelu = itop(float*, ptoi(acts.fch_gelu) + l * B * T * 4*C);
        float* l_fcproj = itop(float*, ptoi(acts.fcproj) + l * B * T * C);
        float* l_residual3 = itop(float*, ptoi(acts.residual3) + l * B * T * C);

        // now do the forward pass
        layernormForward(l_ln1, l_ln1_mean, l_ln1_rstd, residual, l_ln1w, l_ln1b, B, T, C);
        matmulForward(l_qkv, l_ln1, l_qkvw, l_qkvb, B, T, C, 3*C);
        attentionForward(l_atty, l_preatt, l_att, l_qkv, B, T, C, NH);
        matmulForward(l_attproj, l_atty, l_attprojw, l_attprojb, B, T, C, C);
        residualForward(l_residual2, residual, l_attproj, B*T*C);
        layernormForward(l_ln2, l_ln2_mean, l_ln2_rstd, l_residual2, l_ln2w, l_ln2b, B, T, C);
        matmulForward(l_fch, l_ln2, l_fcw, l_fcb, B, T, C, 4*C);
        geluForward(l_fch_gelu, l_fch, B*T*4*C);
        matmulForward(l_fcproj, l_fch_gelu, l_fcprojw, l_fcprojb, B, T, 4*C, C);
        residualForward(l_residual3, l_residual2, l_fcproj, B*T*C);
    }
    residual = itop(float*, ptoi(acts.residual3) + (L-1) * B * T * C); // last residual is in residual3
    layernormForward(acts.lnf, acts.lnf_mean, acts.lnf_rstd, residual, params.lnfw, params.lnfb, B, T, C);
    matmulForward(acts.logits, acts.lnf, params.wte, cast(float*)null, B, T, C, V);
    softmaxForward(acts.probs, acts.logits, B, T, V);

    // also forward the cross-entropy loss function if we have the targets
    if(targets != cast(int*)null) {
        crossentropyForward(model.acts.losses, model.acts.probs, targets, B, T, V);
        // for convenience also evaluate the mean loss
        float mean_loss;
        for(int i=0; i<(B*T); i++) mean_loss += model.acts.losses[i];
        
        mean_loss = mean_loss / (B*T);
        model.mean_loss = mean_loss;
    } else {
        // if we don't have targets, we don't have a loss
        model.mean_loss = cast(float)(-1.0);
    }
}

void gpt2ZeroGrad(GPT2* model) {
    if(model.grads_memory != cast(float*)null) std::memset(model.grads_memory, 0, model.num_parameters * sizeof(float));
    if(model.grads_acts_memory != cast(float*)null) std::memset(model.grads_acts_memory, 0, model.num_activations * sizeof(float));
}

void gpt2Backward(GPT2* model) {
    if(model.mean_loss == cast(float)-1.0) {
        std::println("Error: must forward with targets before backward");
        std::exit(1);
    }

    // lazily allocate the memory for gradients of the weights and activations, if needed
    if(model.grads_memory == cast(float*)null) {
        model.grads_memory = mallocAndPointParameters(model.&grads, cast(int*)model.&param_sizes);
        model.grads_acts_memory = mallocAndPointActivations(model.&grads_acts, cast(int*)model.&act_sizes);
        gpt2ZeroGrad(model);
    }

    // convenience shortcuts
    int B = model.batch_size;
    int T = model.seq_len;
    int V = model.config.vocab_size;
    int L = model.config.num_layers;
    int NH = model.config.num_heads;
    int C = model.config.channels;

    // backward pass: go in the reverse order of the forward pass, and call backward() functions
    ParameterTensors params = model.params; // for brevity
    ParameterTensors grads = model.grads;
    ActivationTensors acts = model.acts;
    ActivationTensors grads_acts = model.grads_acts;

    // we kick off the chain rule by filling in dlosses with 1.0f/(B*T)
    // technically this is a small, inline backward() pass of calculating
    // total, final loss as the mean over all losses over all (B,T) positions in the batch
    float dloss_mean = cast(float)1.0 / (B*T);
    for (int i=0; i<(B*T); i++) grads_acts.losses[i] = dloss_mean;

    crossentropySoftmaxBackward(grads_acts.logits, grads_acts.losses, acts.probs, model.targets, B, T, V);
    matmulBackward(grads_acts.lnf, grads.wte, cast(float*)null, grads_acts.logits, acts.lnf, params.wte, B, T, C, V);
    float* residual = itop(float*, ptoi(acts.residual3) + (L-1) * B * T * C); // last layer's residual
    float* dresidual = itop(float*, ptoi(grads_acts.residual3) + (L-1) * B * T * C); // write to last layer's residual
    layernormBackward(dresidual, grads.lnfw, grads.lnfb, grads_acts.lnf, residual, params.lnfw, acts.lnf_mean, acts.lnf_rstd, B, T, C);

    for(int l=L-1; l>=0; l--) {
        if(l == 0) {
            residual = acts.encoded;
            dresidual = grads_acts.encoded;
        }
        else {
            residual = itop(float*, ptoi(acts.residual3) + (l-1) * B * T * C);
            dresidual = itop(float*, ptoi(grads_acts.residual3) + (l-1) * B * T * C);
        }

        // get the pointers of the weights for this layer
        float* l_ln1w = itop(float*, ptoi(params.ln1w) + l * C);
        float* l_qkvw = itop(float*, ptoi(params.qkvw) + l * 3*C * C);
        float* l_attprojw = itop(float*, ptoi(params.attprojw) + l * C * C);
        float* l_ln2w = itop(float*, ptoi(params.ln2w) + l * C);
        float* l_fcw = itop(float*, ptoi(params.fcw) + l * 4*C * C);
        float* l_fcprojw = itop(float*, ptoi(params.fcprojw) + l * C * 4*C);
        // get the pointers of the gradients of the weights for this layer
        float* dl_ln1w = itop(float*, ptoi(grads.ln1w) + l * C);
        float* dl_ln1b = itop(float*, ptoi(grads.ln1b) + l * C);
        float* dl_qkvw = itop(float*, ptoi(grads.qkvw) + l * 3*C * C);
        float* dl_qkvb = itop(float*, ptoi(grads.qkvb) + l * 3*C);
        float* dl_attprojw = itop(float*, ptoi(grads.attprojw) + l * C * C);
        float* dl_attprojb = itop(float*, ptoi(grads.attprojb) + l * C);
        float* dl_ln2w = itop(float*, ptoi(grads.ln2w) + l * C);
        float* dl_ln2b = itop(float*, ptoi(grads.ln2b) + l * C);
        float* dl_fcw = itop(float*, ptoi(grads.fcw) + l * 4*C * C);
        float* dl_fcb = itop(float*, ptoi(grads.fcb) + l * 4*C);
        float* dl_fcprojw = itop(float*, ptoi(grads.fcprojw) + l * C * 4*C);
        float* dl_fcprojb = itop(float*, ptoi(grads.fcprojb) + l * C);
        // get the pointers of the activations for this layer
        float* l_ln1 = itop(float*, ptoi(acts.ln1) + l * B * T * C);
        float* l_ln1_mean = itop(float*, ptoi(acts.ln1_mean) + l * B * T);
        float* l_ln1_rstd = itop(float*, ptoi(acts.ln1_rstd) + l * B * T);
        float* l_qkv = itop(float*, ptoi(acts.qkv) + l * B * T * 3*C);
        float* l_atty = itop(float*, ptoi(acts.atty) + l * B * T * C);
        float* l_att = itop(float*, ptoi(acts.att) + l * B * NH * T * T);
        float* l_residual2 = itop(float*, ptoi(acts.residual2) + l * B * T * C);
        float* l_ln2 = itop(float*, ptoi(acts.ln2) + l * B * T * C);
        float* l_ln2_mean = itop(float*, ptoi(acts.ln2_mean) + l * B * T);
        float* l_ln2_rstd = itop(float*, ptoi(acts.ln2_rstd) + l * B * T);
        float* l_fch = itop(float*, ptoi(acts.fch) + l * B * T * 4*C);
        float* l_fch_gelu = itop(float*, ptoi(acts.fch_gelu) + l * B * T * 4*C);
        // get the pointers of the gradients of the activations for this layer
        float* dl_ln1 = itop(float*, ptoi(grads_acts.ln1) + l * B * T * C);
        float* dl_qkv = itop(float*, ptoi(grads_acts.qkv) + l * B * T * 3*C);
        float* dl_atty = itop(float*, ptoi(grads_acts.atty) + l * B * T * C);
        float* dl_preatt = itop(float*, ptoi(grads_acts.preatt) + l * B * NH * T * T);
        float* dl_att = itop(float*, ptoi(grads_acts.att) + l * B * NH * T * T);
        float* dl_attproj = itop(float*, ptoi(grads_acts.attproj) + l * B * T * C);
        float* dl_residual2 = itop(float*, ptoi(grads_acts.residual2) + l * B * T * C);
        float* dl_ln2 = itop(float*, ptoi(grads_acts.ln2) + l * B * T * C);
        float* dl_fch = itop(float*, ptoi(grads_acts.fch) + l * B * T * 4*C);
        float* dl_fch_gelu = itop(float*, ptoi(grads_acts.fch_gelu) + l * B * T * 4*C);
        float* dl_fcproj = itop(float*, ptoi(grads_acts.fcproj) + l * B * T * C);
        float* dl_residual3 = itop(float*, ptoi(grads_acts.residual3) + l * B * T * C);

        // backprop this layer
        residualBackward(dl_residual2, dl_fcproj, dl_residual3, B*T*C);
        matmulBackward(dl_fch_gelu, dl_fcprojw, dl_fcprojb, dl_fcproj, l_fch_gelu, l_fcprojw, B, T, 4*C, C);
        geluBackward(dl_fch, l_fch, dl_fch_gelu, B*T*4*C);
        matmulBackward(dl_ln2, dl_fcw, dl_fcb, dl_fch, l_ln2, l_fcw, B, T, C, 4*C);
        layernormBackward(dl_residual2, dl_ln2w, dl_ln2b, dl_ln2, l_residual2, l_ln2w, l_ln2_mean, l_ln2_rstd, B, T, C);
        residualBackward(dresidual, dl_attproj, dl_residual2, B*T*C);
        matmulBackward(dl_atty, dl_attprojw, dl_attprojb, dl_attproj, l_atty, l_attprojw, B, T, C, C);
        attentionBackward(dl_qkv, dl_preatt, dl_att, dl_atty, l_qkv, l_att, B, T, C, NH);
        matmulBackward(dl_ln1, dl_qkvw, dl_qkvb, dl_qkv, l_ln1, l_qkvw, B, T, C, 3*C);
        layernormBackward(dresidual, dl_ln1w, dl_ln1b, dl_ln1, residual, l_ln1w, l_ln1_mean, l_ln1_rstd, B, T, C);
    }
    encoderBackward(grads.wte, grads.wpe, grads_acts.encoded, model.inputs, B, T, C);
}

void gpt2Update(GPT2 *model, float learning_rate, float beta1, float beta2, float eps, float weight_decay, int t) {
    // reference: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html
    // lazily allocate the memory for m_memory and v_memory

    if(model.m_memory == null) {
        model.m_memory = cast(float*)std::calloc(model.num_parameters, sizeof(float));
        model.v_memory = cast(float*)std::calloc(model.num_parameters, sizeof(float));
    }

    for(int i=0; i<model.num_parameters; i++) {
        float param = model.params_memory[i];
        float grad = model.grads_memory[i];

        // update the first moment (momentum)
        float m = beta1 * model.m_memory[i] + (1.0 - beta1) * grad;
        // update the second moment (RMSprop)
        float v = beta2 * model.v_memory[i] + (1.0 - beta2) * grad * grad;
        // bias-correct both moments
        float m_hat = m / (1.0 - std::math::pow(cast(double)beta1, cast(double)t));
        float v_hat = v / (1.0 - std::math::pow(cast(double)beta2, cast(double)t));

        // update
        model.m_memory[i] = m;
        model.v_memory[i] = v;
        model.params_memory[i] -= learning_rate * (m_hat / (std::math::sqrt(cast(double)v_hat) + eps) + weight_decay * param);
    }
}

void gpt2Free(GPT2* model) {
    std::free(cast(void*)model.params_memory);
    std::free(cast(void*)model.grads_memory);
    std::free(cast(void*)model.m_memory);
    std::free(cast(void*)model.v_memory);
    std::free(cast(void*)model.acts_memory);
    std::free(cast(void*)model.grads_acts_memory);
    std::free(cast(void*)model.inputs);
    std::free(cast(void*)model.targets);
}

struct DataLoader {
    // hyperparameters
    int B; // batch size
    int T; // sequence length
    // input handling and its state
    std::file tokens_file;
    long file_size;
    long current_position;
    // output memory
    int* batch;
    int* inputs;
    int* targets;
    // convenience variables
    int num_batches;
}

void dataloaderInit(DataLoader* loader, char* filename, int B, int T) {
    loader.B = B;
    loader.T = T;

    // open the input file for reading
    loader.tokens_file = std::file(filename);
    loader.tokens_file.open("rb");
    if(!(loader.tokens_file.isOpen)) {
        std::println("Error opening tokens file");
        std::exit(1);
    }

    // determine the file size
    libc::fseek(loader.tokens_file._file, 0, libc::seekEnd);
    loader.file_size = libc::ftell(loader.tokens_file._file);
    libc::fseek(loader.tokens_file._file, 0, libc::seekSet);

    if(loader.file_size < ((B * T) + 1) * sizeof(int)) {
        std::println("Error: file size is too small for the batch size and sequence length");
        std::exit(1);
    }
    loader.current_position = 0; // start at the beginning

    // allocate space for B*T + 1 integers to store the inputs and targets
    loader.batch = cast(int*)std::malloc((B * T + 1) * sizeof(int));
    loader.inputs = loader.batch;
    loader.targets = itop(int*, ptoi(loader.batch) + 1); // targets are shifted by one
    loader.num_batches = loader.file_size / (B * T * sizeof(int));
}

void dataloaderReset(DataLoader* loader) {
    loader.current_position = 0;
}

void dataloaderNextBatch(DataLoader* loader) {
    int B = loader.B;
    int T = loader.T;
    // if we are at the end of the file, loop back to the beginning
    if(loader.current_position + (B*T+1) * sizeof(int) > loader.file_size) loader.current_position = 0;
    // read the B*T+1 integers from the file into batch
    libc::fseek(loader.tokens_file._file, loader.current_position, libc::seekSet);
    loader.tokens_file.read(cast(void*)loader.batch, sizeof(int), B*T+1);
    // advance the current position by B*T integers
    loader.current_position += (B*T) * sizeof(int);
}

void dataloaderFree(DataLoader *loader) {
    loader.tokens_file.close();
    std::free(cast(void*)loader.batch);
}

alias gpt2Eot = 50256;

uint randomU32(ulong* state) {
    // xorshift rng: https://en.wikipedia.org/wiki/Xorshift#xorshift.2A
    state[0] = state[0] !! state[0] >. 12;
    state[0] = state[0] !! state[0] <. 25;
    state[0] = state[0] !! state[0] >. 27;
} => (state[0] * cast(ulong)2685821657736338717) >. 32;

float randomF32(ulong* state) => (randomU32(state) >. 8) / cast(float)16777216.0;

int sampleMult(float* probabilities, int n, float coin) {
    // sample index from probabilities (they must sum to 1!)
    // coin is a random number in [0, 1), usually from random_f32()
    float cdf;
    for (int i=0; i<n; i++) {
        cdf += probabilities[i];
        if(coin <cdf) @return(i);
    }
    return = n - 1; // in case of rounding errors
}

struct Tokenizer {
    uint vocab_size;
    char** token_table;
    int init_ok;
}

void safePrintf(char* piece) {
    // the tokens are raw bytes, and we we only want to print the printable ones
    // many bytes can be various control codes, backspace, etc.
    if(piece == null) @return();
    if(piece[0] == '\0') @return();
    // handle individual byte tokens
    // every token is asserted to be at least one byte so doing piece[1] is ok
    if(piece[1] == '\0') {
        uchar byte_val = piece[0];
        if(!(std::ascii::isPrint(byte_val) || std::ascii::isSpace(byte_val))) @return(); // weird byte, don't print it
    }
    std::println(piece);
}

void tokenizerInit(Tokenizer *tokenizer, const char *filename) {
    std::file file = std::file(filename);
    file.open("rb");
    if(!(file.isOpen)) {
        // try to be more helpful as we just added this feature, erase later
        std::println("---");
        std::println("WARNING: Failed to open the tokenizer file ", filename);
        std::println("The Tokenizer is a new feature added April 14 2024.");
        std::println("Re-run `python train_gpt2.py` to write it");
        std::println("---");
        tokenizer.init_ok = 0;
        @return();
    }
    // read in the header
    uint[256] header;
    file.read(cast(void*)&header, sizeof(uint), 256);
    tokenizer.vocab_size = header[2];
    // read in all the tokens
    uchar length;
    tokenizer.token_table = cast(char**)std::malloc(tokenizer.vocab_size * sizeof(char*));
    for(uint i=0; i<tokenizer.vocab_size; i++) {
        file.read(cast(void*)(&length), sizeof(uchar), 1);
        char* token_bytes = cast(char*)std::malloc(length + 1);
        file.read(token_bytes, sizeof(char), cast(int)length);
        token_bytes[length] = '\0';  // Add null terminator for printing
        tokenizer.token_table[i] = token_bytes;
    }
    // cleanups
    file.close();
    tokenizer.init_ok = 1;
}

char* tokenizerDecode(Tokenizer* tokenizer, uint token_id) {
    if(tokenizer.init_ok == 0) return = null;
    if(token_id < tokenizer.vocab_size) {
        return = tokenizer.token_table[token_id];
    } else {
        std::println("invalid token id ", token_id, "!");
        return = null;
    }
}

void tokenizerFree(Tokenizer* tokenizer) {
    if(tokenizer.init_ok == 1) {
        for(uint i=0; i<tokenizer.vocab_size; i++) std::free(cast(void*)tokenizer.token_table[i]);
        std::free(cast(void*)tokenizer.token_table);
    }
}

void main {
    GPT2 model;
    gpt2BuildFromCheckpoint(&model, "gpt2_124M.bin");

    int B = 4;
    int T = 64;

    // TODO

    std::println("Garbage segfault, ignore it.");
}